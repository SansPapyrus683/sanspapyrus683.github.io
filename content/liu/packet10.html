<!DOCTYPE html>
<html lang="en">
<head>
    <link rel="stylesheet" href="../../style-bs/css/fancy.css">
    <link rel="stylesheet" href="../../style-bs/css/classes.css">

    <meta charset="UTF-8">
    <title>liu packet 10</title>
</head>
<body>

<a href="liu_index.html">back to all liu packets</a><br/>
<a href="../../index.html">back to home</a>

<h1>hw packet 10</h1>

<h2>the idea of a confidence interval</h2>

<p>
    <b>point estimate:</b> stat that's a reasonable estimate about the population parameter<br/>
    \(\hat{p} \rightarrow p\), \(\bar{x} \rightarrow \mu\), yeah yeah
</p>

<p>
    for a confidence interval (CI) (A, B),
    the pt. est. is \(\frac{A+B}{2}\), & the margin of error is \(\frac{A-B}{2}\)d
</p>

<p>
    <b>interpretation:</b> "we're [x]% confident that the interval
    from [A] to [B] contains the true [parameter context]"
</p>

<p>
    CIs contain all plausible values, not even sure what this means
</p>

<h2>interpreting the confidence level</h2>

<p>
    <b>interpretation:</b> "if we've a shitton of samples & do a CI for all of 'em,
    ~[x]% of them'll capture the true [parameter context]"
</p>

<h3>margin of error</h3>

<ul>
    <li>confidence level UP, margin of error UP (wider CI)</li>
    <li>sample size (n) UP, margin of error DOWN (narrower CI)</li>
</ul>

<p>
    does acc. for sampling variability, but <b>doesn't</b> acc for nonresponse, undercoverage, or response bias
</p>

<h2>constructing a confidence interval</h2>

<h3>conditions for a CI</h3>

<ol>
    <li>random sample</li>
    <li>10% condition: \(n \leq \frac{1}{10}N \rightarrow\) independence</li>
    <li>
        large counts condition \(n\hat{p}\text{, }n(1-\hat{p}) \geq 10 \rightarrow\)
        can use normal distribution to approximate sampling distribution of \(\hat{p}\)
    </li>
</ol>

<h3>crit z-values</h3>

<ul>
    <li>90% \(z^* \approx 1.645\)</li>
    <li>95% \(z^* \approx 1.960\)</li>
    <li>99% \(z^* \approx 2.576\)</li>
</ul>

<p>
    you need the normal distribution graph at minimum for work,
    but you can also include the \(\text{invNorm}\) thing if you wanna make sure
</p>

<h3>confidence interval for a value of \(\hat{p}\)</h3>

\[\hat{p} \pm z^* \cdot \sqrt{\frac{\hat{p}(1-\hat{p})}{n}}\]

<p>
    btw the \(\sqrt{\frac{\hat{p}(1-\hat{p})}{n}}\) is called the standard error,
    and is referred to as \(SE_{\hat{p}}\)
</p>

<p>
    <b>SIDE NOTE:</b> given that on the WS for the "parameter:" and "statistic:" question he put
    "p = true [whatever]" and "\(\hat{p}\) = point estimate of [whatever]", we should probably do that asw
</p>

<h2>estimating a pop. prop: 4-step process</h2>

<h3>4-step process</h3>

<h4>it's called the "one sample z interval for p"</h4>

<ol>
    <li><b>state:</b> parameter & confidence level</li>
    <li><b>plan:</b> name the procedure & check the conditions (rng, large counts, etc.)</li>
    <li><b>do:</b> general & specific formulas, plug in & calc</li>
    <li><b>conclude:</b> interpret interval in context</li>
</ol>

<h3>choosing \(n\)</h3>

\[ME=z^* \sqrt{\frac{\hat{p}(1-\hat{p})}{n}} \qquad n=\frac{\hat{p}(1-\hat{p})}{(\frac{ME}{z^*})^2}\]

<p>
    if you don't know \(\hat{p}\), set it as 0.5 for the worst-case scenario<br/>
    also you should <b>always round \(n\) up</b>, if you don't you'll die irl, trust me
</p>

<h2>significance tests: the basics</h2>

<h3>types of hypotheses</h3>

<p>
    \(H_0\), or "it was probably nothing": \(p\) or \(\mu\) is equal to the base claim
</p>

<p>
    \(H_a\), or "it's something.": \(p\) or \(\mu\) is &lt;, &gt;, or \(\neq\) the base claim (null value)
</p>

<p>
    <b>interpretation of P-val:</b> "assuming \(H_0\) is valid, or [ctx], there's a ~[P-val] chance of getting
    the deserved result or something more extreme due to sampling variability"
</p>

<p>
    <b>how to conclude:</b> "because the P-value [&lt;/&gt;] \(\alpha\), we [do/don't] have convincing
    evidence for \(H_a\) context"
</p>

<p>
    if the P-value is less than \(\alpha\), it's convincing<br/>
    if it's greater than \(\alpha\), it's not<br/>
    if it's exactly equal to \(\alpha\), then idk, maybe not to be more conservative<br/>
</p>

<h2>significance test for p</h2>

<p>
    <b>conditions:</b> literally the same as those of a CI
</p>

<h3>standardized test statistic (z-score)</h3>

<img src="img/packet10/normal.png" alt="normal thing" class="half-img center"/>

<p>
    couple of things about this normal plot
</p>

<ul>
    <li>\(\mu_{\hat{p}}=p\)</li>
    <li>\(\sigma_{\hat{p}}=\sqrt{\frac{p(1-p)}{n}}\)- we use base p bc we're presuming the null hypo. is true</li>
    <li>\(z=\frac{\hat{p}-p}{\sqrt{\frac{p(1-p)}{n}}}\)</li>
</ul>

<p>
    btw, if the p-val &lt; \(\alpha\) (5%), it's called "statistically significant",
    aka we've convincing evidence for the [ctx]
</p>

<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

</body>
</html>
